{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phcli Jupyter Template\n",
    "# \n",
    "# 使用手册：\n",
    "# 1. 请将全局变量定义在第一个输入区内\n",
    "# 2. Phcli 会自动在第二个输入区初始化 Spark Session\n",
    "# 3. 所有 print 会在 phcli maxauto dag 后自动转为 logger.debug() 方法\n",
    "# 4. 请在第三个输入区开始编码，phcli maxauto dag 后会全部归类为一个方法\n",
    "\n",
    "\n",
    "# Config defined in here\n",
    "\n",
    "############## == config == ###################\n",
    "job_name = \"delivery\"\n",
    "job_runtime = \"python3\"\n",
    "job_command = \"submit\"\n",
    "job_timeout = 720.0\n",
    "############## == config == ###################\n",
    "\n",
    "\n",
    "# Variables defined in here\n",
    "\n",
    "############## == input args == ###################\n",
    "a = 123\n",
    "b = 456\n",
    "############## == input args == ###################\n",
    "\n",
    "############## == output args == ###################\n",
    "c = 'abc'\n",
    "d = 'def'\n",
    "############## == output args == ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# ENV\n",
    "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/local/spark\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAWPBDTVEAEU44ZAGT\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"cn-northwest-1\"\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"Jupyter Keep-Alive Session\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instance\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from phcli.ph_logs.ph_logs import phs3logger\n",
    "# from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as func\n",
    "import os\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, col, udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Gilead\"\n",
    "time_left = \"202001\"\n",
    "time_right = \"202011\"\n",
    "out_dir = \"202011\"\n",
    "extract_path = \"s3a://ph-stream/common/public/max_result/0.0.5/max_standard\"\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAX数据交付\n",
    "'''\n",
    "time_left = int(time_left)\n",
    "time_right = int(time_right)\n",
    "\n",
    "product_map_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/prod_mapping\"\n",
    "max_standard_path = extract_path + \"/\" + project_name + \"_max_standard\"\n",
    "raw_data_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/product_mapping_out\"\n",
    "province_city_mapping_path = max_path + '/' + project_name + '/province_city_mapping'\n",
    "if project_name == 'Gilead':\n",
    "    corp_mapping_path = max_path + \"/Gilead/FOR_MAX_standardization/corp_mapping\"\n",
    "    brand_mapping_path = max_path + \"/Gilead/FOR_MAX_standardization/brand_mapping\"\n",
    "\n",
    "# 输出\n",
    "time_range = str(time_left) + '_' + str(time_right)\n",
    "out_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/\" + project_name + \"_max_delivery_\" + time_range + '.csv'\n",
    "out2_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/\" + project_name + \"_max_delivery_\" + time_range + '_others.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========  数据执行  ============\n",
    "\n",
    "# ====  一. 函数定义  ====\n",
    "\n",
    "def deal_ID_length(df):\n",
    "    # ID不足7位的补足0到6位\n",
    "    # 国药诚信医院编码长度是7位数字，cpa医院编码是6位数字。\n",
    "    df = df.withColumn(\"ID\", df[\"ID\"].cast(StringType()))\n",
    "    # 去掉末尾的.0\n",
    "    df = df.withColumn(\"ID\", func.regexp_replace(\"ID\", \"\\\\.0\", \"\"))\n",
    "    df = df.withColumn(\"ID\", func.when(func.length(df.ID) < 7, func.lpad(df.ID, 6, \"0\")).otherwise(df.ID))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====  二. 数据准备  ====  \n",
    "\n",
    "# 产品信息，列名标准化\n",
    "product_map = spark.read.parquet(product_map_path)\n",
    "# a. 列名清洗统一\n",
    "# 有的min2结尾有空格与无空格的是两条不同的匹配\n",
    "if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "    product_map = product_map.withColumnRenamed(product_map.columns[21], \"pfc\")\n",
    "if project_name == \"Eisai\":\n",
    "    product_map = product_map.withColumnRenamed(product_map.columns[22], \"pfc\")\n",
    "\n",
    "for i in product_map.columns:\n",
    "    if i in [\"标准通用名\", \"通用名_标准\", \"药品名称_标准\", \"S_Molecule_Name\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"通用名\")\n",
    "    if i in [\"min1_标准\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"min2\")\n",
    "    if i in [\"packcode\", \"Pack_ID\", \"Pack_Id\", \"PackID\", \"packid\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"pfc\")\n",
    "    if i in [\"商品名_标准\", \"S_Product_Name\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准商品名\")\n",
    "    if i in [\"剂型_标准\", \"Form_std\", \"S_Dosage\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准剂型\")\n",
    "    if i in [\"规格_标准\", \"Specifications_std\", \"药品规格_标准\", \"S_Pack\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准规格\")\n",
    "    if i in [\"包装数量2\", \"包装数量_标准\", \"Pack_Number_std\", \"S_PackNumber\", \"最小包装数量\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准包装数量\")\n",
    "    if i in [\"标准企业\", \"生产企业_标准\", \"Manufacturer_std\", \"S_CORPORATION\", \"标准生产厂家\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准生产企业\")\n",
    "if project_name == \"Janssen\" or project_name == \"NHWA\":\n",
    "    if \"标准剂型\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"剂型\", \"标准剂型\")\n",
    "    if \"标准规格\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"规格\", \"标准规格\")\n",
    "    if \"标准生产企业\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"生产企业\", \"标准生产企业\")\n",
    "    if \"标准包装数量\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"包装数量\", \"标准包装数量\")\n",
    "\n",
    "# b. min2处理\n",
    "product_map = product_map.withColumn(\"min2\", func.regexp_replace(\"min2\", \"&amp;\", \"&\")) \\\n",
    "                .withColumn(\"min2\", func.regexp_replace(\"min2\", \"&lt;\", \"<\")) \\\n",
    "                .withColumn(\"min2\", func.regexp_replace(\"min2\", \"&gt;\", \">\"))\n",
    "\n",
    "if 'Route' not in product_map.columns:\n",
    "    product_map = product_map.withColumn('Route', func.lit('-'))\n",
    "    \n",
    "# b. 选取需要的列\n",
    "product_map = product_map \\\n",
    "                .select(\"min2\", \"pfc\", \"通用名\", \"标准商品名\", \"标准剂型\", \"标准规格\", \"标准包装数量\", \"标准生产企业\", 'Route') \\\n",
    "                .withColumn(\"pfc\", product_map[\"pfc\"].cast(IntegerType())) \\\n",
    "                .withColumn(\"标准包装数量\", product_map[\"标准包装数量\"].cast(IntegerType())) \\\n",
    "                .withColumnRenamed(\"pfc\", \"PACK_ID\") \\\n",
    "                .distinct()\n",
    "\n",
    "# c. pfc为0统一替换为null\n",
    "product_map = product_map.withColumn(\"PACK_ID\", func.when(col('PACK_ID') == 0, None).otherwise(col('PACK_ID'))).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====  Max =====\n",
    "monthlist = range(time_left, time_right+1, 1)\n",
    "path_list = [max_standard_path + '/Date_copy=' + str(i) for i in monthlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for eachpath in path_list:\n",
    "    df = spark.read.parquet(eachpath)\n",
    "    if index ==0:\n",
    "        data_standard = df\n",
    "    else:\n",
    "        data_standard = data_standard.union(df)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales，Units 处理\n",
    "'''\n",
    "包装数量为空的是others， Sales 或者 Units 可以为0\n",
    "包装数量不为空的，Sales和Units只要有一列为0，那么都调整为0；Units先四舍五入为整数，然后变化的系数乘以Sales获得新的Sales\n",
    "Sales 保留两位小数\n",
    "负值调整为0\n",
    "去掉 Sales，Units 同时为0的行\n",
    "'''\n",
    "data_standard_0 = data_standard.withColumn(\"Predict_Sales\", col(\"Predict_Sales\").cast(DoubleType())) \\\n",
    "                        .withColumn(\"Predict_Unit\", col(\"Predict_Unit\").cast(DoubleType()))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"Units\", func.when((~col(\"标准包装数量\").isNull()) & (col('Predict_Unit') <= 0), func.lit(0)) \\\n",
    "                                                                .otherwise(func.round(col('Predict_Unit'), 0)))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"p\", col('Units')/col('Predict_Unit'))\n",
    "data_standard_0 = data_standard_0.withColumn(\"p\", func.when((~col(\"标准包装数量\").isNull()) & (col(\"p\").isNull()), func.lit(0)) \\\n",
    "                                                    .otherwise(col('p')))\n",
    "data_standard_0 = data_standard_0.withColumn(\"p\", func.when((col(\"标准包装数量\").isNull()) & (col(\"p\").isNull()), func.lit(1)) \\\n",
    "                                                    .otherwise(col('p')))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"Sales\", col('Predict_Sales') * col('p'))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"Sales\", func.round(col('Sales'), 2)) \\\n",
    "                            .withColumn(\"Units\", col(\"Units\").cast(IntegerType())) \\\n",
    "                            .drop(\"Predict_Unit\", \"Predict_Sales\", \"p\")\n",
    "# 负值调整为0\n",
    "data_standard_0 = data_standard_0.withColumn(\"Sales\", func.when(col('Sales') < 0 , func.lit(0)).otherwise(col('Sales'))) \\\n",
    "                                .withColumn(\"Units\", func.when(col('Sales') == 0, func.lit(0)).otherwise(col('Units')))\n",
    "\n",
    "# 去掉 Sales，Units 同时为0的行\n",
    "data_standard_1 = data_standard_0.where(col(\"标准包装数量\").isNull())\n",
    "data_standard_2 = data_standard_0.where((~col(\"标准包装数量\").isNull()) & (col('Sales') != 0) & (col('Units') != 0))\n",
    "\n",
    "data_standard_3 =  data_standard_1.union(data_standard_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信息匹配，group计算\n",
    "max_standard_delivery = data_standard_3.select(\"Province\", \"City\", \"Date\", \"Prod_Name\", \"Molecule\", \"PANEL\", \"DOI\", \"Prod_Name\",\n",
    "                                            \"Sales\", \"Units\")\n",
    "max_standard_delivery = max_standard_delivery.join(product_map.dropDuplicates(['min2']), max_standard_delivery.Prod_Name == product_map.min2, how='left')\n",
    "max_standard_delivery = max_standard_delivery.groupby([\"Date\", \"Province\", \"City\", \"Molecule\", \"标准商品名\", \"标准剂型\", \"标准规格\", \n",
    "                                                       \"标准包装数量\", \"标准生产企业\", \"Prod_Name\", \"DOI\", \"Route\"]) \\\n",
    "                                            .agg(func.sum('Sales').alias('金额'), func.sum('Units').alias('数量'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名重命名\n",
    "max_standard_delivery_out = max_standard_delivery.withColumnRenamed('Date', '年月') \\\n",
    "                                                .withColumnRenamed('Province', '省份') \\\n",
    "                                                .withColumnRenamed('City', '城市') \\\n",
    "                                                .withColumnRenamed('Molecule', '通用名') \\\n",
    "                                                .withColumnRenamed('标准商品名', '商品名') \\\n",
    "                                                .withColumnRenamed('标准剂型', '剂型') \\\n",
    "                                                .withColumnRenamed('标准规格', '规格') \\\n",
    "                                                .withColumnRenamed('标准包装数量', '包装数量') \\\n",
    "                                                .withColumnRenamed('标准生产企业', '生产企业') \\\n",
    "                                                .withColumnRenamed('DOI', '市场名') \\\n",
    "                                                .withColumnRenamed('Route', '给药途径')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交付结果\n",
    "model_1_list = ['贝达', '神州', '康哲', '奥鸿', '京新']\n",
    "if project_name in model_1_list:\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                       \"包装数量\", \"生产企业\", \"金额\", \"数量\")    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_list = ['奥鸿']\n",
    "if project_name in model_2_list:\n",
    "    df = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"Prod_Name\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "\n",
    "    province_city_mapping = spark.read.parquet(province_city_mapping_path)\n",
    "    province_city_mapping = deal_ID_length(province_city_mapping)\n",
    "    province_city_mapping = province_city_mapping.select('ID', 'Province', 'City').distinct()\n",
    "\n",
    "    raw_data = spark.read.parquet(raw_data_path)\n",
    "    raw_data = deal_ID_length(raw_data)\n",
    "    raw_data_info = raw_data.where((col('year_month') >= time_left) & (col('year_month') <= time_right)) \\\n",
    "                        .drop('Province', 'City') \\\n",
    "                        .join(province_city_mapping, on='ID', how='left') \\\n",
    "                        .select('year_month', 'Province', 'min2') \\\n",
    "                        .withColumn('f_raw', func.concat_ws('+', col('year_month'), col('Province'), col('min2'))) \\\n",
    "                        .select('f_raw').distinct()\n",
    "    ## 这四个省样本量不足 删掉邦亭，其他省取样本有的所有产品\n",
    "    province_delete = ['甘肃省','广西壮族自治区','青海省','西藏自治区']\n",
    "\n",
    "    df2 = df.withColumn('f_max', func.concat_ws('+', col('年月'), col('省份'), col('Prod_Name')))\n",
    "    df3 = df2.join(raw_data_info, df2.f_max == raw_data_info.f_raw, how='left')\n",
    "    df4 = df3.withColumn('delete', func.when(~(col('f_raw').isNull()) | (col('省份').isin(province_delete) & col('Prod_Name').contains('邦亭')), \n",
    "                                              func.lit(0)).otherwise(func.lit(1)))\n",
    "\n",
    "    out1 = df4.where(col('delete') == 0).drop('f_raw', 'f_max', 'delete')\n",
    "    out2 = df4.where(col('delete') == 1).drop('f_raw', 'f_max', 'delete')\n",
    "    \n",
    "    out1 = out1.repartition(1)\n",
    "    out1.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)\n",
    "    \n",
    "    out2 = out2.repartition(1)\n",
    "    out2.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_list = ['海坤']\n",
    "if project_name in model_3_list:\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    # 城市名修改\n",
    "    @udf(StringType())\n",
    "    def city_change(name):\n",
    "        # 城市名统一\n",
    "        dict = {\"毕节市\":\"毕节地区\", \"哈密市\":\"哈密地区\", \"日喀则市\":\"日喀则地区\", \"楚雄彝族自治州\":\"楚雄市\"}\n",
    "        if name in dict.keys():\n",
    "            newname = dict[name]\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    out = out.withColumn('城市', city_change(col('城市')))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_list = ['汇宇']\n",
    "if project_name in model_4_list:\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    out = out.where(~col('通用名').isin('多西他赛','培美曲塞'))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5_list = ['Tide']\n",
    "if project_name in model_5_list:\n",
    "    out = max_standard_delivery_out.select(\"市场名\", \"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    # 城市名修改\n",
    "    @udf(StringType())\n",
    "    def city_change(name):\n",
    "        # 城市名统一\n",
    "        dict = {\"毕节市\":\"毕节地区\", \"哈密市\":\"哈密地区\", \"日喀则市\":\"日喀则地区\", \"楚雄彝族自治州\":\"楚雄市\"}\n",
    "        if name in dict.keys():\n",
    "            newname = dict[name]\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    @udf(StringType())\n",
    "    def province_change(name):\n",
    "        # 城市名统一\n",
    "        dict = {\"内蒙\":\"内蒙古\", \"黑龙\":\"黑龙江\"}\n",
    "        if name in dict.keys():\n",
    "            newname = dict[name]\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    out = out.withColumn('城市', city_change(col('城市'))) \\\n",
    "            .withColumn('省份', func.substring(col('省份'), 0, 2)) \\\n",
    "            .withColumn('省份', province_change(col('省份'))) \\\n",
    "            .withColumn('市场名', func.when((col('通用名') == '氟比洛芬') & (col('剂型') == '注射剂'), func.lit('凯纷')).otherwise(col('市场名')))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_list = ['Gilead']\n",
    "if project_name in model_6_list:\n",
    "    df = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\", \"给药途径\")\n",
    "    df = df.withColumnRenamed('金额', '销售金额') \\\n",
    "            .withColumnRenamed('数量', '销售数量（最小单位:片支）') \\\n",
    "    \n",
    "    corp_mapping = spark.read.parquet(corp_mapping_path)\n",
    "    corp_mapping = corp_mapping.where(~col('Corp_STD_EN').isNull()) \\\n",
    "                                .select(corp_mapping.columns[0:3]).distinct() \\\n",
    "                                .withColumnRenamed('Corporation', '生产企业')\n",
    "    \n",
    "    brand_mapping = spark.read.parquet(brand_mapping_path)\n",
    "    brand_mapping = brand_mapping.where(~col('Molecue_STD_EN').isNull()) \\\n",
    "                                .select(brand_mapping.columns[1:8]).distinct() \\\n",
    "                                .withColumnRenamed('DrugName_Molecue', '通用名') \\\n",
    "                                .withColumnRenamed('ProductName', '商品名') \\\n",
    "                                .withColumnRenamed('Corp_CN', '生产企业')\n",
    "    \n",
    "    df2 = df.join(brand_mapping, on=['通用名', '商品名', '生产企业'], how='left') \\\n",
    "           .join(corp_mapping, on=['生产企业'], how='left')\n",
    "    \n",
    "    @udf(StringType())\n",
    "    def Corp_change(name, corp, brand, std):\n",
    "        # 公司名修改    \n",
    "        if corp == '株洲千金药业股份有限公司' and brand == '艾普丁':\n",
    "            if std == 'EN':\n",
    "                newname = 'HN.QIANJIN XIELI'\n",
    "            elif std == 'CN':\n",
    "                newname = '湖南千金协力药业有限公司'\n",
    "        elif corp == '株洲千金药业股份有限公司' and (brand in ['健甘灵','乾力安']):\n",
    "            if std == 'EN':\n",
    "                newname = 'QIANJINXIANGJIANG'\n",
    "            elif std == 'CN':\n",
    "                newname = '湖南千金湘江药业股份有限公司'\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    out = df2.withColumn('Corp_STD_EN', Corp_change(col('Corp_STD_EN'), col('生产企业'), col('商品名'), func.lit('EN'))) \\\n",
    "            .withColumn('Corp_STD_CN', Corp_change(col('Corp_STD_CN'), col('生产企业'), col('商品名'), func.lit('CN')))\n",
    "    \n",
    "    out = out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \"包装数量\", \"生产企业\", \"销售金额\", \"销售数量（最小单位:片支）\", \n",
    "                     \"给药途径\", \"Molecue_STD_EN\", \"Molecue_STD_CN\", \"Brand_STD_EN\", \"Brand_STD_CN\", \"Corp_STD_EN\", \"Corp_STD_CN\")\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41217"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(销售金额)=2382299269.9700065, sum(销售数量（最小单位:片支）)=904569312)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out.agg(func.sum('金额'), func.sum('数量')).collect()\n",
    "out.agg(func.sum('销售金额'), func.sum('销售数量（最小单位:片支）')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+----+----+----+----+--------+--------+-------------------------+--------+--------------+--------------+------------+------------+-----------+-----------+\n",
      "|生产企业|通用名|商品名|年月|省份|城市|剂型|规格|包装数量|销售金额|销售数量（最小单位:片支）|给药途径|Molecue_STD_EN|Molecue_STD_CN|Brand_STD_EN|Brand_STD_CN|Corp_STD_EN|Corp_STD_CN|\n",
      "+--------+------+------+----+----+----+----+----+--------+--------+-------------------------+--------+--------------+--------------+------------+------------+-----------+-----------+\n",
      "|       0|     0|     0|   0|   0|   0|   0|   0|       0|       0|                        0|       0|             0|             0|         154|         101|         84|         84|\n",
      "+--------+------+------+----+----+----+----+----+--------+--------+-------------------------+--------+--------------+--------------+------------+------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 空值情况\n",
    "out.agg(*[func.count(func.when(func.isnull(c), c)).alias(c) for c in out.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------+----------------+------+------+-----+--------+-------------------------------------+------------------+-------------------------+--------+--------------------+----------------+--------------------+------------------------+------------------+-------------------------------------+\n",
      "|  年月|            省份|      城市|          通用名|商品名|  剂型| 规格|包装数量|                             生产企业|          销售金额|销售数量（最小单位:片支）|给药途径|      Molecue_STD_EN|  Molecue_STD_CN|        Brand_STD_EN|            Brand_STD_CN|       Corp_STD_EN|                          Corp_STD_CN|\n",
      "+------+----------------+----------+----------------+------+------+-----+--------+-------------------------------------+------------------+-------------------------+--------+--------------------+----------------+--------------------+------------------------+------------------+-------------------------------------+\n",
      "|202001|    内蒙古自治区|锡林郭勒盟|替诺福韦二吡呋酯|纳信得|  片剂|300MG|      30|                     齐鲁制药有限公司|             78.59|                      271|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|TENOFOVIR DISOPRO...|富马酸替诺福韦二吡呋酯片|  QILU PHARM GROUP|                         齐鲁制药集团|\n",
      "|202001|          辽宁省|    丹东市|替诺福韦二吡呋酯|纳信得|  片剂|300MG|      30|                     齐鲁制药有限公司|5296.5599999999995|                    18264|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|TENOFOVIR DISOPRO...|富马酸替诺福韦二吡呋酯片|  QILU PHARM GROUP|                         齐鲁制药集团|\n",
      "|202001|          吉林省|    通化市|        恩替卡韦|  木泽|  片剂|0.5MG|      28|             北京百奥药业有限责任公司|           12567.5|                    63980|      OR|           ENTECAVIR|        恩替卡韦|ENTECAVIR        ...|                    木泽|    BJ.BAIAO PHARM|             北京百奥药业有限责任公司|\n",
      "|202001|          福建省|    龙岩市|      阿德福韦酯|贺维力|  片剂| 10MG|      14|                      葛兰素-史克集团|           5056.77|                      359|      OR|  ADEFOVIR DIPIVOXIL|      阿德福韦酯|HEPSERA          ...|                  贺维力|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|          山东省|    泰安市|      阿德福韦酯|贺维力|  片剂| 10MG|      14|                      葛兰素-史克集团|116100.79999999999|                     7978|      OR|  ADEFOVIR DIPIVOXIL|      阿德福韦酯|HEPSERA          ...|                  贺维力|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|          广东省|    东莞市|      阿德福韦酯|贺维力|  片剂| 10MG|      14|                      葛兰素-史克集团|          45179.57|                     3317|      OR|  ADEFOVIR DIPIVOXIL|      阿德福韦酯|HEPSERA          ...|                  贺维力|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|          山东省|    烟台市|        拉米夫定|贺甘定|  片剂|100MG|      14|               福建广生堂药业有限公司|           46249.2|                    15948|      OR|          LAMIVUDINE|        拉米夫定|HE GAN DING      ...|                  贺甘定| FJ.COSUNTER PHARM|           福建广生堂药业股份有限公司|\n",
      "|202001|          福建省|    漳州市|        替比夫定|素比伏|  片剂|600MG|       7|                             诺华集团|          82657.95|                     4698|      OR|         TELBIVUDINE|        替比夫定|SEBIVO           ...|                  素比伏|    NOVARTIS GROUP|                             诺华集团|\n",
      "|202001|          吉林省|    吉林市|        替比夫定|素比伏|  片剂|600MG|       7|                             诺华集团|           94517.0|                     5243|      OR|         TELBIVUDINE|        替比夫定|SEBIVO           ...|                  素比伏|    NOVARTIS GROUP|                             诺华集团|\n",
      "|202001|          江西省|    抚州市|替诺福韦二吡呋酯|韦瑞德|  片剂|300MG|      30|                      葛兰素-史克集团|24318.399999999998|                     2305|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|VIREAD           ...|                  韦瑞德|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|          浙江省|    湖州市|替诺福韦二吡呋酯|韦瑞德|  片剂|300MG|      30|                      葛兰素-史克集团|         143414.44|                    13061|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|VIREAD           ...|                  韦瑞德|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|          安徽省|    六安市|替诺福韦二吡呋酯|韦瑞德|  片剂|300MG|      30|                      葛兰素-史克集团|          118923.0|                     7281|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|VIREAD           ...|                  韦瑞德|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|          广东省|    汕尾市|替诺福韦二吡呋酯|韦瑞德|  片剂|300MG|      30|                      葛兰素-史克集团|          53034.33|                     3247|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|VIREAD           ...|                  韦瑞德|GLAXOSMITHKL GROUP|                       葛兰素史克集团|\n",
      "|202001|新疆维吾尔自治区|  吐鲁番市|      阿德福韦酯|亿来芬|  片剂| 10MG|      14|                     齐鲁制药有限公司|            137.34|                       42|      OR|  ADEFOVIR DIPIVOXIL|      阿德福韦酯|YI LAI FEN       ...|                  亿来芬|  QILU PHARM GROUP|                         齐鲁制药集团|\n",
      "|202001|          湖南省|    邵阳市|替诺福韦二吡呋酯|  倍信|  片剂|300MG|      30|                 成都倍特药业有限公司|          28873.86|                    61961|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|BEI XIN          ...|                    倍信|SC.BRILILIANT PHAR|                 成都倍特药业有限公司|\n",
      "|202001|  广西壮族自治区|    钦州市|        恩替卡韦|  润众|  片剂|0.5MG|       7|                             正大集团|          63411.43|                     4932|      OR|           ENTECAVIR|        恩替卡韦|RUN ZHONG        ...|                    润众|  C.T-TIANQING GP.|                     正大天晴制药集团|\n",
      "|202001|          广东省|    清远市|      阿德福韦酯|  粤宝|  片剂| 10MG|      14|广东肇庆星湖生物科技股份有限公司星...|           1701.54|                     1233|      OR|  ADEFOVIR DIPIVOXIL|      阿德福韦酯|YUE BAO          ...|                    粤宝|  GD.ZQ.XINGHU BIO|广东肇庆星湖生物科技股份有限公司星...|\n",
      "|202001|          贵州省|    铜仁市|        恩替卡韦|恩甘定|胶囊剂|0.5MG|      28|               福建广生堂药业有限公司|          12258.09|                    44627|      OR|           ENTECAVIR|        恩替卡韦|EGD              ...|                  恩甘定| FJ.COSUNTER PHARM|           福建广生堂药业股份有限公司|\n",
      "|202001|          山东省|    滨州市|      阿德福韦酯|  名正|胶囊剂| 10MG|      14|                             正大集团|          12201.63|                     3408|      OR|  ADEFOVIR DIPIVOXIL|      阿德福韦酯|MING ZHENG       ...|                    名正|  C.T-TIANQING GP.|                     正大天晴制药集团|\n",
      "|202001|          山西省|    忻州市|替诺福韦二吡呋酯|  代韦|  片剂|300MG|      30|           杭州苏泊尔南洋药业有限公司|            437.09|                     1153|      OR|TENOFOVIR DISOPROXIL|替诺福韦二吡呋酯|TENOFOVIR DISOPRO...|                    代韦|ZJ.SUPOR SOUTHOCEA|           杭州苏泊尔南洋药业有限公司|\n",
      "+------+----------------+----------+----------------+------+------+-----+--------+-------------------------------------+------------------+-------------------------+--------+--------------------+----------------+--------------------+------------------------+------------------+-------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
